{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "expired-virginia",
   "metadata": {},
   "source": [
    "# Sortino ratio optimisation with risk budgetting\n",
    "\n",
    "The objective of this program is to maximise the Sortino ratio of the portfolio such that all stocks have a weight allocation of at least min_weight and a maximum weight allocation of max_weight. Moreover, each stock cannot have more than an x percentage contribution to the total portfolio volatility. \n",
    "\n",
    "The package scipy.optimize can only minimise the objective function. Hence, the negative Sortino Ratio is minimised. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coral-iraqi",
   "metadata": {},
   "source": [
    "## Definition Sortino ratio\n",
    "The Sortino ratio is a measure that uses a risk-adjusted return measure based on downside risk. This differs from the Sharpe ratio, as this measure makes use of the total (positive and negative) volatility. The Sortino ratio is calculated in the following way:\n",
    "\n",
    "$ \\text{Sortino ratio} = \\frac{R_p-B}{\\sigma_d} $ \\\n",
    " Where $R_p$: portfolio return \\\n",
    "$\\hspace{1.05cm}$  $B$: benchmark \\\n",
    "$\\hspace{1.1cm}$  $\\sigma_d$: downside risk of the portfolio. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mature-studio",
   "metadata": {},
   "source": [
    "## Downside risk // semi deviation w.r.t. B\n",
    "\n",
    "Variance of a stock A: $\\sigma^2_A=\\frac{1}{T} \\sum_{t=1}^T (min\\{R^{A}_t-B_t,0\\})^2$\n",
    "\n",
    "Covariance of stocks A and C: $\\sigma_A\\sigma_C=\\frac{1}{T} \\sum_{t=1}^T min\\{R^{A}_t-B_t,0\\}*min\\{R^{C}_t-B_t,0\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "assisted-spain",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_datareader as dr \n",
    "from datetime import datetime\n",
    "from scipy.optimize import minimize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "postal-drinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages installation anaconda + version used\n",
    " # conda install pandas=1.2.2\n",
    " # conda install pandas-datareader=0.9.0\n",
    " # conda install scipy=1.6.1\n",
    " # conda install openpyxl=3.0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-glasgow",
   "metadata": {},
   "source": [
    "### Predefined values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "hawaiian-judge",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = \"MSCI\"\n",
    "min_weight = 0.025\n",
    "max_weight = 1\n",
    "max_risk_contribution = 0.40\n",
    "max_risk_contribution_industry = 0.60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-stamp",
   "metadata": {},
   "source": [
    "### Data preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "popular-penalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariance(returnsA, returnsB):\n",
    "    # Multiply min{R_{ta}-B, 0}*min{R_{tc}-B, 0}\n",
    "    multiplication = returnsA*returnsB  \n",
    "    # Obtain T\n",
    "    t = multiplication.count()\n",
    "    # Sum over all t = {1,2,...,T}\n",
    "    summation = multiplication.sum(axis=0)\n",
    "    # Calculate downside variance and convert them to yearly values\n",
    "    downside_variance = 1/(t)*summation*252\n",
    "    return downside_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "motivated-cheese",
   "metadata": {},
   "outputs": [],
   "source": [
    "def covarianceMatrix(assetlist, step1data):\n",
    "    covariance_matrix = np.zeros((len(assetlist), len(assetlist)))\n",
    "    \n",
    "    # loop for indices [0,n-2] -> all elements except [0][n-1], [n-1][0], [n-1][n-1], where n = len(assets)\n",
    "    for x in range(len(assetlist)-1):\n",
    "        # variance\n",
    "        covariance_matrix[x][x] = covariance(step1data[assetlist[x]], step1data[assetlist[x]])\n",
    "        # covariance\n",
    "        value = covariance(step1data[assetlist[x]], step1data[assetlist[x+1]])\n",
    "        covariance_matrix[x][x+1] = value\n",
    "        covariance_matrix[x+1][x] = value\n",
    "    \n",
    "    # Set missing values\n",
    "    index = len(assetlist) - 1\n",
    "    covariance_matrix[index][index] = covariance(step1data[assetlist[index]], step1data[assetlist[index]])\n",
    "    value = covariance(step1data[assetlist[index]], step1data[assetlist[0]])\n",
    "    covariance_matrix[0][index] = value\n",
    "    covariance_matrix[index][0] = value\n",
    "\n",
    "    return(covariance_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-moisture",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "preceding-injury",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_excel('SigmaInputMetIndex.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ignored-hopkins",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Input Data\n",
    "start_date = '2021-01-01'\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "assets = test[\"Ticker\"].tolist()\n",
    "assets.append(benchmark)\n",
    "\n",
    "# Create df for adjusted close prices of portfolio\n",
    "prices = pd.DataFrame()\n",
    "\n",
    "for stock in assets:\n",
    "    prices[stock] = dr.data.get_data_yahoo(stock, start =start_date, end =today)['Adj Close']\n",
    "\n",
    "#Show the daily simple return\n",
    "returns = (prices/prices.shift(1))-1\n",
    "\n",
    "#return_stocks.to_excel('PortfolioReturns.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "shared-remains",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substract the benchmark returns from the stock returns and take the min{Rt-Bt, 0}\n",
    "step1 = returns.subtract(returns[\"MSCI\"], axis=0)\n",
    "step1[step1 > 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "related-soccer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3301054071127133\n"
     ]
    }
   ],
   "source": [
    "# Benchmark return\n",
    "bm_return = returns[benchmark].mean()*252\n",
    "print(bm_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "instructional-adaptation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove benchmark data from the return values and the assetlist\n",
    "assets.remove(benchmark)\n",
    "del returns[benchmark]\n",
    "del step1[benchmark]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aerial-handbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covariance matrix\n",
    "cov_matrix = covarianceMatrix(assets, step1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organizational-filling",
   "metadata": {},
   "source": [
    "### Optimisation functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "coordinate-nightmare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to obtain portfolio-{return,volatility,sortino}\n",
    "def get_p_data(weights):\n",
    "        weights = np.array(weights)\n",
    "        p_return= np.sum(returns.mean()*weights) * 252 # Taken from the positive and negative returns -> still multiply  by 252\n",
    "        p_volatility = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights))) # Takes the downside risk as a risk measure -> already multiplied by 252\n",
    "        p_sortino = (p_return-bm_return)/p_volatility \n",
    "        return np.array([p_return, p_volatility, p_sortino])\n",
    "\n",
    "def get_p_volatility(weights):\n",
    "        weights = np.array(weights)\n",
    "        p_volatility = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "        return p_volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "local-chorus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the marginal volatilities \n",
    "def marginal_volatilities(weights, cov_matrix):\n",
    "    volatility_p = get_p_volatility(weights)\n",
    "    print(\"portfolio volatility = \", volatility_p )\n",
    "        \n",
    "    for i in range(len(weights)):\n",
    "        cov_weight_i = (weights[i] * np.dot(cov_matrix, weights)[i])/volatility_p \n",
    "        print(\"i = \", i , \"risk = \", cov_weight_i, \"  % = \", (cov_weight_i/volatility_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "environmental-small",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get negative Sortino Ratio.\n",
    "def negative_sortino(weights):\n",
    "        return get_p_data(weights)[2] * -1\n",
    "\n",
    "# Function to check if sum investment is 1.\n",
    "def check_sum(weights):\n",
    "        return np.sum(weights) -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "engaging-opinion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that puts a maximum on the risk contribution of one stock\n",
    "# args is defined as the tuple of arguments with first the max risk contribution and then the covariance matrix\n",
    "def risk_budget(weights, i, *args):\n",
    "    volatility_p = get_p_volatility(weights)\n",
    "    dot_product = np.dot(args[1], weights)\n",
    "    dot_product_value = np.take(dot_product, i)\n",
    "    q = args[0]*volatility_p - (weights[i]*dot_product_value/volatility_p)\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "inappropriate-patio",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that puts a maximum on the risk contribution of one industry\n",
    "# args is defined as the tuple of arguments with first the max risk contribution and then the covariance matrix\n",
    "def volatilities_industry(weights, stocks, *args):\n",
    "    industry_volatility = 0\n",
    "    volatility_p = get_p_volatility(weights)\n",
    "    \n",
    "    # Add the volatility of a stock (in percentage of the total portfolio) to the share of volatility of the industry\n",
    "    for stock in stocks:\n",
    "        cov_weight_stock = (weights[assets.index(stock)] * np.dot(args[1], weights)[assets.index(stock)])/volatility_p \n",
    "        percentage = cov_weight_stock/volatility_p\n",
    "        industry_volatility =  industry_volatility + percentage\n",
    "    \n",
    "    # Make sure that the industry volatility does not exceed the max risk contribution (args[0])\n",
    "    industry_volatility = args[0] - industry_volatility\n",
    "    return industry_volatility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-floating",
   "metadata": {},
   "source": [
    "### Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "greater-irish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constraints\n",
    "constraints_list = list()\n",
    "\n",
    "#  sum investment is 1\n",
    "constraints_list.append({'type':'eq', 'fun':check_sum})\n",
    "\n",
    "# individual risk constributions\n",
    "a = list(range(len(assets)))\n",
    "for i in a:\n",
    "    constraints_list.append({'type':'ineq', 'fun': risk_budget, 'args':(i, max_risk_contribution, cov_matrix)})  \n",
    "\n",
    "for x in test.Industry.unique():\n",
    "    temp = test.query('Industry ==' + str(x))['Ticker'] \n",
    "    constraints_list.append({'type':'ineq', 'fun': volatilities_industry, 'args':(temp, max_risk_contribution_industry, cov_matrix)})\n",
    "\n",
    "constraints = tuple(constraints_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "entitled-reader",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight boundaries\n",
    "bounds = ((min_weight,max_weight),)*len(assets)\n",
    "\n",
    "# Equally weighted portfolio / starting point of Sequantial least Squares programming method.\n",
    "equally_weighted = [1/len(assets),]*len(assets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "moral-plasma",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tessa\\envs\\lib\\site-packages\\scipy\\optimize\\optimize.py:283: RuntimeWarning: Values in x were outside bounds during a minimize step, clipping to bounds\n",
      "  \"minimize step, clipping to bounds\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Optimisation method and results\n",
    "optimal_result = minimize(negative_sortino, equally_weighted, method='SLSQP', bounds=bounds, constraints = constraints)\n",
    "optimal_weights = optimal_result.x\n",
    "optimal_portfolio = get_p_data(optimal_result.x)\n",
    "\n",
    "optimal_return = np.round(optimal_portfolio[0],2)\n",
    "optimal_volatility = np.round(optimal_portfolio[1],2)\n",
    "optimal_sortino = np.round(optimal_portfolio[2],2)\n",
    "overview = pd.DataFrame({'Assets': assets,'Weight (%)': np.round(optimal_weights*100,2)}, columns=['Assets', 'Weight (%)']).T\n",
    "\n",
    "statistic = ['Number of Assets', 'Expected Return', 'Expected Volatility', 'Expected Sortino']\n",
    "data = [np.round(len(assets),0), optimal_return, optimal_volatility, optimal_sortino]\n",
    "table = pd.DataFrame(data, statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "naval-findings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0      1      2    3       4    5     6    7    8    9   ...  \\\n",
      "Assets      HEN.DE  AD.AS    DHI   MA  ALV.DE  JPM  EQIX  MDT  NVO  UNH  ...   \n",
      "Weight (%)     2.5    2.5  15.52  2.5     2.5  2.5   2.5  2.5  2.5  2.5  ...   \n",
      "\n",
      "                16    17   18    19       20   21      22    23     24     25  \n",
      "Assets      DTE.DE  NFLX  ETN  NVDA  PHIA.AS  SAP  KER.PA  SPGI  TCEHY   AMAT  \n",
      "Weight (%)     2.5   2.5  2.5   2.5      2.5  2.5     2.5   2.5    2.5  11.56  \n",
      "\n",
      "[2 rows x 26 columns]\n",
      "                         0\n",
      "Number of Assets     26.00\n",
      "Expected Return       0.80\n",
      "Expected Volatility   0.08\n",
      "Expected Sortino      5.74\n"
     ]
    }
   ],
   "source": [
    "# Results\n",
    "print(overview)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "congressional-plastic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# marginal_volatilities(optimal_weights, cov_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "harmful-infrared",
   "metadata": {},
   "outputs": [],
   "source": [
    "def volatilities_industry_achteraf(weights, stocks, cov_matrix):\n",
    "    industry_volatility = 0\n",
    "    volatility_p = get_p_volatility(weights)\n",
    "        \n",
    "    for stock in stocks:\n",
    "        cov_weight_stock = (weights[assets.index(stock)] * np.dot(cov_matrix, weights)[assets.index(stock)])/volatility_p \n",
    "        percentage = cov_weight_stock/volatility_p\n",
    "        industry_volatility =  industry_volatility + percentage\n",
    "        \n",
    "    return industry_volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "brief-armenia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Industry  1  % volatility:  0.32768527363705363\n",
      "Industry  2  % volatility:  0.06329583066287559\n",
      "Industry  3  % volatility:  0.07515377102177383\n",
      "Industry  4  % volatility:  0.44245036911924107\n",
      "Industry  5  % volatility:  0.09141475555905591\n"
     ]
    }
   ],
   "source": [
    "for x in test.Industry.unique():\n",
    "    #List of stocks that belong to the same industry x\n",
    "    temp = test.query('Industry ==' + str(x))['Ticker']  \n",
    "    a=volatilities_industry_achteraf(optimal_weights, temp, cov_matrix)\n",
    "    print(\"Industry \", x, \" % volatility: \", a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
