{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "expired-virginia",
   "metadata": {},
   "source": [
    "# Sortino ratio optimisation with risk budgetting\n",
    "\n",
    "The objective of this program is to maximise the Sortino ratio of the portfolio such that all stocks have a weight allocation of at least min_weight and a maximum weight allocation of max_weight. Moreover, each stock cannot have more than an x percentage contribution to the total portfolio volatility. \n",
    "\n",
    "The package scipy.optimize can only minimise the objective function. Hence, the negative Sortino Ratio is minimised. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coral-iraqi",
   "metadata": {},
   "source": [
    "## Definition Sortino ratio\n",
    "The Sortino ratio is a measure that uses a risk-adjusted return measure based on downside risk. This differs from the Sharpe ratio, as this measure makes use of the total (positive and negative) volatility. The Sortino ratio is calculated in the following way:\n",
    "\n",
    "$ \\text{Sortino ratio} = \\frac{R_p-B}{\\sigma_d} $ \\\n",
    " Where $R_p$: portfolio return \\\n",
    "$\\hspace{1.05cm}$  $B$: benchmark \\\n",
    "$\\hspace{1.1cm}$  $\\sigma_d$: downside risk of the portfolio. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mature-studio",
   "metadata": {},
   "source": [
    "## Downside risk // semi deviation w.r.t. B\n",
    "\n",
    "Variance of a stock A: $\\sigma^2_A=\\frac{1}{T} \\sum_{t=1}^T (min\\{R^{A}_t-B_t,0\\})^2$\n",
    "\n",
    "Covariance of stocks A and C: $\\sigma_A\\sigma_C=\\frac{1}{T} \\sum_{t=1}^T min\\{R^{A}_t-B_t,0\\}*min\\{R^{C}_t-B_t,0\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "assisted-spain",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_datareader as dr \n",
    "from datetime import datetime\n",
    "from scipy.optimize import minimize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "postal-drinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages installation anaconda + version used\n",
    " # conda install pandas=1.2.2\n",
    " # conda install pandas-datareader=0.9.0\n",
    " # conda install scipy=1.6.1\n",
    " # conda install openpyxl=3.0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-glasgow",
   "metadata": {},
   "source": [
    "### Predefined values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "hawaiian-judge",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = \"MSCI\"\n",
    "min_weight = 0.025\n",
    "max_weight = 1\n",
    "max_risk_contribution = 0.40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-stamp",
   "metadata": {},
   "source": [
    "### Data preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "popular-penalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariance(returnsA, returnsB):\n",
    "    # Multiply min{R_{ta}-B, 0}*min{R_{tc}-B, 0}\n",
    "    multiplication = returnsA*returnsB  \n",
    "    # Obtain T\n",
    "    t = multiplication.count()\n",
    "    # Sum over all t = {1,2,...,T}\n",
    "    summation = multiplication.sum(axis=0)\n",
    "    # Calculate downside variance and convert them to yearly values\n",
    "    downside_variance = 1/(t)*summation*252\n",
    "    return downside_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "motivated-cheese",
   "metadata": {},
   "outputs": [],
   "source": [
    "def covarianceMatrix(assetlist, step1data):\n",
    "    covariance_matrix = np.zeros((len(assetlist), len(assetlist)))\n",
    "    \n",
    "    # loop for indices [0,n-2] -> all elements except [0][n-1], [n-1][0], [n-1][n-1], where n = len(assets)\n",
    "    for x in range(len(assetlist)-1):\n",
    "        # variance\n",
    "        covariance_matrix[x][x] = covariance(step1data[assetlist[x]], step1data[assetlist[x]])\n",
    "        # covariance\n",
    "        value = covariance(step1data[assetlist[x]], step1data[assetlist[x+1]])\n",
    "        covariance_matrix[x][x+1] = value\n",
    "        covariance_matrix[x+1][x] = value\n",
    "    \n",
    "    # Set missing values\n",
    "    index = len(assetlist) - 1\n",
    "    covariance_matrix[index][index] = covariance(step1data[assetlist[index]], step1data[assetlist[index]])\n",
    "    value = covariance(step1data[assetlist[index]], step1data[assetlist[0]])\n",
    "    covariance_matrix[0][index] = value\n",
    "    covariance_matrix[index][0] = value\n",
    "\n",
    "    return(covariance_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-moisture",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ignored-hopkins",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Input Data\n",
    "start_date = '2017-01-01'\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "#assets = pd.read_excel ('SigmaInput.xlsx')[\"Ticker\"]\n",
    "assets = [\"AD.AS\", \"BABA\",\"PVH\"]\n",
    "assets.append(benchmark)\n",
    "\n",
    "# Create df for adjusted close prices of portfolio\n",
    "prices = pd.DataFrame()\n",
    "\n",
    "for stock in assets:\n",
    "    prices[stock] = dr.data.get_data_yahoo(stock, start =start_date, end =today)['Adj Close']\n",
    "\n",
    "#Show the daily simple return\n",
    "returns = (prices/prices.shift(1))-1\n",
    "\n",
    "#return_stocks.to_excel('PortfolioReturns.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "shared-remains",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substract the benchmark returns from the stock returns and take the min{Rt-Bt, 0}\n",
    "step1 = returns.subtract(returns[\"MSCI\"], axis=0)\n",
    "step1[step1 > 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "related-soccer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49550457021629807\n"
     ]
    }
   ],
   "source": [
    "# Benchmark return\n",
    "bm_return = returns[benchmark].mean()*252\n",
    "print(bm_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "instructional-adaptation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove benchmark data from the return values and the assetlist\n",
    "assets.remove(benchmark)\n",
    "del returns[benchmark]\n",
    "del step1[benchmark]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "aerial-handbook",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.08365098 0.04913222 0.05165868]\n",
      " [0.04913222 0.07580991 0.04878006]\n",
      " [0.05165868 0.04878006 0.1344632 ]]\n",
      "['AD.AS', 'BABA', 'PVH']\n"
     ]
    }
   ],
   "source": [
    "# Covariance matrix\n",
    "cov_matrix = covarianceMatrix(assets, step1)\n",
    "print(cov_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organizational-filling",
   "metadata": {},
   "source": [
    "### Optimisation functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "coordinate-nightmare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to obtain portfolio-{return,volatility,sortino}\n",
    "def get_p_data(weights):\n",
    "        weights = np.array(weights)\n",
    "        p_return= np.sum(returns.mean()*weights) * 252 # Taken from the positive and negative returns -> still multiply  by 252\n",
    "        p_volatility = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights))) # Takes the downside risk as a risk measure -> already multiplied by 252\n",
    "        p_sortino = (p_return-bm_return)/p_volatility \n",
    "        return np.array([p_return, p_volatility, p_sortino])\n",
    "\n",
    "def get_p_volatility(weights):\n",
    "        weights = np.array(weights)\n",
    "        p_volatility = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "        return p_volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "local-chorus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the marginal volatilities \n",
    "def marginal_volatilities(weights, cov_matrix_np):\n",
    "    volatility_p = get_p_volatility(weights)\n",
    "    print(\"portfolio volatility = \", volatility_p )\n",
    "        \n",
    "    for i in range(len(weights)):\n",
    "        cov_weight_i = (weights[i] * np.dot(cov_matrix_np, weights)[i])/volatility_p \n",
    "        print(\"i = \", i , \"risk = \", cov_weight_i, \"  % = \", (cov_weight_i/volatility_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "environmental-small",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get negative Sortino Ratio.\n",
    "def negative_sortino(weights):\n",
    "        return get_p_data(weights)[2] * -1\n",
    "\n",
    "# function to check if sum investment is 1.\n",
    "def check_sum(weights):\n",
    "        return np.sum(weights) -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "engaging-opinion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args is defined as the tuple of arguments with first the max risk contribution and then the covariance matrix\n",
    "def risk_budget(weights, i, *args):\n",
    "    volatility_p = get_p_volatility(weights)\n",
    "    dot_product = np.dot(args[1], weights)\n",
    "    dot_product_value = np.take(dot_product, i)\n",
    "    q = args[0]*volatility_p - (weights[i]*dot_product_value/volatility_p)\n",
    "    return q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-floating",
   "metadata": {},
   "source": [
    "### Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "greater-irish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constraints\n",
    "constraints_list = list()\n",
    "\n",
    "#  sum investment is 1\n",
    "constraints_list.append({'type':'eq', 'fun':check_sum})\n",
    "\n",
    "# individual risk constributions\n",
    "a = list(range(len(assets)))\n",
    "for i in a:\n",
    "    constraints_list.append({'type':'ineq', 'fun': risk_budget, 'args':(i, max_risk_contribution, cov_matrix)})  \n",
    "\n",
    "constraints = tuple(constraints_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "entitled-reader",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight boundaries\n",
    "bounds = ((min_weight,max_weight),)*len(assets)\n",
    "\n",
    "# Equally weighted portfolio / starting point of Sequantial least Squares programming method.\n",
    "equally_weighted = [1/len(assets),]*len(assets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "moral-plasma",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimisation method and results\n",
    "optimal_result = minimize(negative_sortino, equally_weighted, method='SLSQP', bounds=bounds, constraints = constraints)\n",
    "optimal_weights = optimal_result.x\n",
    "optimal_portfolio = get_p_data(optimal_result.x)\n",
    "\n",
    "optimal_return = np.round(optimal_portfolio[0],2)\n",
    "optimal_volatility = np.round(optimal_portfolio[1],2)\n",
    "optimal_sortino = np.round(optimal_portfolio[2],2)\n",
    "overview = pd.DataFrame({'Assets': assets,'Weight (%)': np.round(optimal_weights*100,2)}, columns=['Assets', 'Weight (%)']).T\n",
    "\n",
    "statistic = ['Number of Assets', 'Expected Return', 'Expected Volatility', 'Expected Sortino']\n",
    "data = [np.round(len(assets),0), optimal_return, optimal_volatility, optimal_sortino]\n",
    "table = pd.DataFrame(data, statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "naval-findings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0      1      2\n",
      "Assets      AD.AS   BABA    PVH\n",
      "Weight (%)   22.8  43.51  33.69\n",
      "                        0\n",
      "Number of Assets     3.00\n",
      "Expected Return      0.22\n",
      "Expected Volatility  0.26\n",
      "Expected Sortino    -1.08\n"
     ]
    }
   ],
   "source": [
    "# Results\n",
    "print(overview)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "congressional-plastic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "portfolio volatility =  0.2568009471317037\n",
      "i =  0 risk =  0.05136018942703716   % =  0.20000000000271193\n",
      "i =  1 risk =  0.1027203788531726   % =  0.40000000000191244\n",
      "i =  2 risk =  0.10272037885149395   % =  0.39999999999537567\n"
     ]
    }
   ],
   "source": [
    "marginal_volatilities(optimal_weights, cov_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
