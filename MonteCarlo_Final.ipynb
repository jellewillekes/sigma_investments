{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Simulation including backtesting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader\n",
    "from pandas_datareader import data as wb\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, gmean, cauchy #Package for statistic calculations on distributions\n",
    "import seaborn as sns  #Package for statistical data visualization\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "start = '2010-01-01'\n",
    "end = '2015-01-01' \n",
    "forecast = '2016-01-01'\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "   \n",
    "rf = 0.0078\n",
    "\n",
    "days = 252\n",
    "iterations = 10000\n",
    "\n",
    "benchmark = '^GSPC'\n",
    "stocks = ['NOVO-B.CO','WM', 'TSLA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo Simulation for n assets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Stock Prices from Yahoo Finance and Calculate (log) Returns\n",
    "\n",
    "Generally, simple returns are used for cross-section perspectives. This is comparing values at one specific point in time (i.e. using calculating Covariance Matrix or Sharpe ratio). \n",
    "\n",
    "Log returns are used for statistical evaluation (i.e. MSPE and R-square calculations). Log returns mainly used in time-series. Moreover, stock returns is assumed to have a Log Normal Distribution, therefore Log return is used for statistical evaluation. (comes in handy in analyzing MC simulation as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_prices(tickers, start, end):\n",
    "    prices = pd.DataFrame()\n",
    "    if len([tickers]) ==1:\n",
    "        prices[tickers] = wb.DataReader(tickers, data_source = 'yahoo', start = start, end = end)['Adj Close']\n",
    "        prices = pd.DataFrame(prices)\n",
    "    else:\n",
    "        for t in tickers:\n",
    "            prices[t] = wb.DataReader(t, data_source = 'yahoo', start = start, end = end)['Adj Close']\n",
    "    return(prices)\n",
    "\n",
    "def returns(prices):\n",
    "    return ((prices/prices.shift(1))-1)\n",
    "\n",
    "def log_returns(prices):\n",
    "    return (np.log(1+prices.pct_change())) #(prices/prices.shift(1))-1) does not work here. Div0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Market Data (Benchmark) and Assets Statistics (CAPM, SD, Beta and Sharpe) Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some calculations to calculate some basic info/statistics such as Expected return from CAPM model. As well as SD, Beta and Sharpe ratio over historical time period. Note: not a main part of the simulation itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_prices_combination(prices, benchmark, start):\n",
    "    benchmark_prices = stock_prices(benchmark, start, end)\n",
    "    benchmark_returns = log_returns(benchmark_prices).dropna()\n",
    "    annual_return = np.exp(benchmark_returns.mean()*252).values-1\n",
    "    prices = prices.merge(benchmark_prices, left_index=True, right_index=True)\n",
    "    return prices, annual_return\n",
    "\n",
    "def calculate_statistics(prices, benchmark = benchmark, start=start, riskfree = rf):\n",
    "    # Beta\n",
    "    prices, benchmark_return = benchmark_prices_combination(prices, benchmark, start) #function returns both DF of prices and annual return benchmark. \n",
    "    log_return = log_returns(prices)\n",
    "    cov_matrix = log_return.cov()*252\n",
    "    covariance = pd.DataFrame(cov_matrix.iloc[:-1,-1]) # finds covariance of all individual assets with benchmark\n",
    "    market_variance = log_return.iloc[:,-1].var()*252  # finds variance in log returns of benchmark\n",
    "    beta = covariance/market_variance \n",
    "    \n",
    "    # SD\n",
    "    sd_assets = pd.DataFrame(((log_return.std()*250**0.5)[:-1]), columns=['STD']) #Calculate SD of asset returns, translate to yearly and skip SD of benchmark.\n",
    "    beta = beta.merge(sd_assets, left_index=True, right_index=True) # add sd of assets to dataframe of beta.\n",
    "    \n",
    "    # CAPM\n",
    "    for i, row in beta.iterrows(): # loop through panda rows (for all assets)\n",
    "        beta.at[i,'CAPM'] = riskfree + (row[benchmark] * (benchmark_return-riskfree)) # Calc expected return based on CAPM model.\n",
    "    \n",
    "    # Sharpe\n",
    "    for i, row in beta.iterrows():\n",
    "        beta.at[i,'Sharpe'] = ((row['CAPM']-riskfree)/(row['STD'])) # Calculate Sharpe of individual assets based on CAPM return. \n",
    "    \n",
    "    beta.rename(columns={benchmark:\"Beta\"}, inplace=True) #rename column of Beta\n",
    "    \n",
    "    return beta #return complete dataframe containing all statistics called beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometric Brownian Motion\n",
    "Brownian motion is a stochastic process used for modeling random behavior over time. The price at day t depends on the asset price at day t-1 and the simulated expected return for day t. The motion has two main components:\n",
    "1. Drift - \n",
    "The direction that rates of returns have had in the past. Also know as the historical return of a stock. Assume for now that the historical return of a stock is equal to it's expected return. In the drift calculation, half of the variance is deducted from the expected return. This because historical values are eroded in the future. In other words, if you take the menan of historical returns you \"over-estimate\" the mean (\"expected\") return. On the other hand, the mean of the future returns is fixed. \n",
    "2. Volatility/SD - \n",
    "To account for a error-term in the calculation of future returns we include a random standard normal variable multiplied by the historical standard deviation. At this point we generate random paths in the expected asset prices. For every single time we will simulate the formula (expected asset price at t) we will find a slightly different value.\n",
    "\n",
    "The asset pricing equation looks as follows:\n",
    "$$\n",
    "{Price_{i}}={Price_{i-1} * e^{mean-\\frac{1}{2}{Var} + SD * Z(n(0,1))}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_drift(prices):\n",
    "    returns = log_returns(prices)\n",
    "    mean = returns.mean()\n",
    "    variance = returns.var()\n",
    "    drift = mean-(0.5*variance)\n",
    "    try:\n",
    "        return drift.values # return array of sd \n",
    "    except AttributeError:\n",
    "        return drift        # return only data type float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_returns(prices, days, iterations):\n",
    "    drift = calculate_drift(prices)\n",
    "    try:\n",
    "        sd = log_returns(prices).std().values   # returns array of sd (preferred)\n",
    "    except AttributeError:\n",
    "        sd = log_returns(prices).std()          # returns only data type float64\n",
    "    \n",
    "    random_numbers = np.random.rand(days, iterations) # generated np array of lengts days x iterations\n",
    "    normal_random = norm.ppf(random_numbers)    # normalize the random numbers generated by a one-tailed test\n",
    "    daily_returns = np.exp(drift + sd * normal_random) # calc daily returns by formula of GBM\n",
    "    \n",
    "    return daily_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to simulate prices\n",
    "For every t in days (days is the number of days we forecast the stock price) we obtain iterations different options of asset prices at t. In the following function we calculate the asset prices for every day t in days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_prices(prices, days, iterations):\n",
    "    \n",
    "    returns = daily_returns(prices, days, iterations) # Generate iterations daily returns for days days.\n",
    "    simulated_prices = np.zeros_like(returns)         # Create empty np array. \n",
    "    simulated_prices[0] = prices.iloc[-2]             # Actual price in the first row of matrix. \n",
    "    \n",
    "    for t in range(1,days): # Calculate the price of each day\n",
    "        simulated_prices[t] = simulated_prices[t-1]*returns[t]  # Fill the matrix by looping through numer of days.\n",
    "           \n",
    "    return pd.DataFrame(simulated_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to collect and summarize random paths of asset prices of all assets in input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo(tickers, days, iterations, start, end):\n",
    "    prices = stock_prices(tickers, start, end)\n",
    "    simulated_prices_DF = []\n",
    "    \n",
    "    for t in range(len(tickers)): \n",
    "        simulated_prices = simulate_prices(prices.iloc[:,t], (days), iterations)        \n",
    "       \n",
    "        simulated_prices['ticker'] = tickers[t] # Add column with tickers to np array and append to dataframe.\n",
    "        column = simulated_prices.columns.tolist()\n",
    "        column = column[-1:] + column[:-1]\n",
    "        simulated_prices = simulated_prices[column]\n",
    "        simulated_prices_DF.append(simulated_prices)\n",
    "     \n",
    "    simulated_prices_DF = pd.concat(simulated_prices_DF)\n",
    "    return simulated_prices_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to calculate simulated (yearly) returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_returns(tickers, days, iterations, start, end):\n",
    "    prices = stock_prices(tickers, start, end)\n",
    "    actual_prices = list(prices.iloc[-2])\n",
    "    \n",
    "    simulated_assets = monte_carlo(tickers, days, iterations, start, end = end)\n",
    "    average_prices = list(simulated_assets.mean(axis=1))\n",
    "    average_prices.reverse()\n",
    "    average_prices = average_prices[::252]\n",
    "    average_prices.reverse()\n",
    "\n",
    "    returns = []\n",
    "\n",
    "    for i in range(len(tickers)):\n",
    "        return_i = 100 * ((average_prices[i] / actual_prices[i]) -1)\n",
    "        returns.append(return_i)\n",
    "    \n",
    "    returns = [round(return_i, 2) for return_i in returns]\n",
    "    \n",
    "    simulated_returns = pd.DataFrame({\"Ticker\": tickers, \"Simulated Return (%)\": returns})\n",
    "    simulated_returns = simulated_returns.sort_values(by = ['Simulated Return (%)'], ascending = False)\n",
    "    tickers = simulated_returns.iloc[:,0] #arrange ticker list in descending order\n",
    "    \n",
    "    return simulated_returns, tickers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to calculate mean return over historical period and forecasted period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulated_mean_prices(tickers, days, iterations, start, end):\n",
    "    simulated_assets = monte_carlo(tickers, days, iterations, start, end = end)\n",
    "    #print(simulated_assets)\n",
    "    simulated_assets[\"mean\"] = simulated_assets.mean(axis=1)\n",
    "    #print(simulated_assets)\n",
    "    \n",
    "    simulated_mean_prices = pd.DataFrame()\n",
    "    for x in range(len(tickers)):\n",
    "        begin_a = 0 + days*x\n",
    "        end_a = days + days*x\n",
    "        simulated_mean_prices[tickers[x]] = simulated_assets[begin_a:end_a][\"mean\"] \n",
    "        \n",
    "    return simulated_mean_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to compare forecasted returns with actual returns for day days of forecasted stock prices\n",
    "\n",
    "Note that this result is not very interesting because it is a statistic of a specific moment in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_returns(tickers, days, iterations, start, end, forecast):\n",
    "    simulated_returns, tickers = simulate_returns(tickers, days, iterations, start, end)\n",
    "    actual_prices = stock_prices(tickers, end, forecast)\n",
    "    start_prices = list(actual_prices.iloc[1])\n",
    "    final_prices = list(actual_prices.iloc[-2])\n",
    "\n",
    "    actual_returns = []\n",
    "\n",
    "    for i in range(len(tickers)):\n",
    "        return_i = 100 * ((final_prices[i] - start_prices[i]) / start_prices[i])\n",
    "        actual_returns.append(return_i)\n",
    "\n",
    "    actual_returns = [round(return_i, 2) for return_i in actual_returns]\n",
    "    simulated_returns['Actual Return (%)'] = actual_returns\n",
    "    compared_returns = simulated_returns\n",
    "    return compared_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAPE (Mean Absolute Percentage Error)\n",
    "The mean absolute percentage error (MAPE) is a statistical measure of how accurate a forecast system is. It measures this accuracy as a percentage, and can be calculated as the average absolute percent error for each time period minus actual values divided by actual values. Where At is the actual value and Ft is the forecast value, this is given by:\n",
    "\n",
    "MAPE = $\\frac{100\\%}{n}\\sum_{t=1}^{n}\\left |\\frac{A_t - F_t}{A_t}\\right|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(actual, predicted): \n",
    "    mape = 0\n",
    "    n=0\n",
    "    \n",
    "    for x in range(len(actual)):\n",
    "        a = abs((actual[x]-predicted[x])/predicted[x])\n",
    "        if np.isnan(a) == False:\n",
    "            n += 1\n",
    "            mape = mape + a\n",
    "    mape = mape/n\n",
    "\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to compare forecasted prices to actual results\n",
    "Using the correlation and MAPE as measures of prediction accuracy testing the results of the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_results(tickers, days, iterations, start, end, forecast):\n",
    "    simulated_prices = simulated_mean_prices(tickers, days, iterations, start, end)\n",
    "    temp_prices = stock_prices(tickers, end, forecast) #Deze heeft de tijd (datums) in de dataframe die zorgen voor problemen met de correlatie\n",
    "    \n",
    "    actual_prices = pd.DataFrame()\n",
    "    for x in range(len(tickers)):\n",
    "        a = np.array(temp_prices[tickers[x]])\n",
    "        actual_prices[tickers[x]] = a\n",
    "\n",
    "    correlations = simulated_prices.corrwith(actual_prices, drop = True)\n",
    "    \n",
    "    mape_data = []\n",
    "    for x in range(len(tickers)):\n",
    "        m = mape(actual_prices[tickers[x]],simulated_prices[tickers[x]])\n",
    "        mape_data.append(m)\n",
    "    \n",
    "    accuracy_results = pd.DataFrame({\"Correlation\": correlations, \"MAPE\": mape_data})\n",
    "    \n",
    "    return accuracy_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to compare the accuracy results of different intervals of historical periods\n",
    "In the following function we aim to find the best historical period to use in the MC simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_period(tickers, days, iterations, start, end, forecast):\n",
    "    startingdates = []\n",
    "    s = int(re.search(r'\\d+', start).group()) # First year\n",
    "    e = int(re.search(r'\\d+', end).group()) # Last year\n",
    "\n",
    "    # Create a list with all possible startingyears\n",
    "    for a in range(s,e):\n",
    "        b = start.replace(str(s), str(a))\n",
    "        startingdates.append(b)\n",
    "    \n",
    "    #Statistics for correlation\n",
    "    minimum = []\n",
    "    maximum = []\n",
    "    mean = []\n",
    "    percentage = []\n",
    "    enddate = []\n",
    "\n",
    "    #Statistics for MAPE\n",
    "    high = []\n",
    "    good = []\n",
    "    reasonable = []\n",
    "    inaccurate = []\n",
    "    \n",
    "    for startingdate in startingdates:\n",
    "        enddate.append(end)\n",
    "        results = accuracy_results(tickers, days, iterations, start, end, forecast)\n",
    "        minimum.append(min(results[\"Correlation\"]))\n",
    "        maximum.append(max(results[\"Correlation\"]))\n",
    "        mean.append(gmean(results[\"Correlation\"]))\n",
    "        percentage.append((len([i for i in results[\"Correlation\"] if i > 0.3])/len(results[\"Correlation\"])) )\n",
    "        high.append((len([i for i in results[\"MAPE\"] if i <= 0.10])/len(results[\"MAPE\"])))\n",
    "        good.append((len([i for i in results[\"MAPE\"] if i > 0.10 and i <= 0.20])/len(results[\"MAPE\"])))\n",
    "        reasonable.append((len([i for i in results[\"MAPE\"] if i > 0.20 and i <= 0.50])/len(results[\"MAPE\"])))\n",
    "        inaccurate.append((len([i for i in results[\"MAPE\"] if i > 0.50])/len(results[\"MAPE\"])))\n",
    "        print(startingdate)\n",
    "        print(results)\n",
    "    \n",
    "    corr_comparison = pd.DataFrame({\"Begindate\": startingdates, \"Enddate\": enddate, \"Min\": minimum, \"Max\": maximum, \"Mean\": mean,\"% above 0.75\": percentage})\n",
    "    mape_comparison = pd.DataFrame({\"Begindate\": startingdates, \"Enddate\": enddate, \"Highly accurate\": high, \"Good\": good, \"Reasonable\": reasonable, \"Inaccurate\": inaccurate})\n",
    "    \n",
    "    \n",
    "    return corr_comparison, mape_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010-01-01\n",
      "           Correlation      MAPE\n",
      "NOVO-B.CO     0.675513  0.212288\n",
      "WM            0.177494  0.056490\n",
      "TSLA          0.349103  0.193922\n",
      "2011-01-01\n",
      "           Correlation      MAPE\n",
      "NOVO-B.CO     0.673784  0.213338\n",
      "WM            0.185961  0.054816\n",
      "TSLA          0.365125  0.188643\n",
      "2012-01-01\n",
      "           Correlation      MAPE\n",
      "NOVO-B.CO     0.673991  0.211774\n",
      "WM            0.175058  0.058623\n",
      "TSLA          0.365994  0.189958\n",
      "2013-01-01\n",
      "           Correlation      MAPE\n",
      "NOVO-B.CO     0.678466  0.209388\n",
      "WM            0.194858  0.055611\n",
      "TSLA          0.345776  0.186607\n",
      "2014-01-01\n",
      "           Correlation      MAPE\n",
      "NOVO-B.CO     0.675219  0.210918\n",
      "WM            0.186053  0.055656\n",
      "TSLA          0.356583  0.189993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(    Begindate     Enddate       Min       Max      Mean  % above 0.75\n",
       " 0  2010-01-01  2015-01-01  0.177494  0.675513  0.347208      0.666667\n",
       " 1  2011-01-01  2015-01-01  0.185961  0.673784  0.357653      0.666667\n",
       " 2  2012-01-01  2015-01-01  0.175058  0.673991  0.350835      0.666667\n",
       " 3  2013-01-01  2015-01-01  0.194858  0.678466  0.357559      0.666667\n",
       " 4  2014-01-01  2015-01-01  0.186053  0.675219  0.355151      0.666667,\n",
       "     Begindate     Enddate  Highly accurate      Good  Reasonable  Inaccurate\n",
       " 0  2010-01-01  2015-01-01         0.333333  0.333333    0.333333         0.0\n",
       " 1  2011-01-01  2015-01-01         0.333333  0.333333    0.333333         0.0\n",
       " 2  2012-01-01  2015-01-01         0.333333  0.333333    0.333333         0.0\n",
       " 3  2013-01-01  2015-01-01         0.333333  0.333333    0.333333         0.0\n",
       " 4  2014-01-01  2015-01-01         0.333333  0.333333    0.333333         0.0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_period(stocks, 257, 10000, start, end, forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
